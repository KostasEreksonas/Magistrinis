{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c86923-4acd-4312-b1ab-aaec6dca7776",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import matthews_corrcoef, accuracy_score, root_mean_squared_error, mean_squared_error, mean_absolute_error, precision_score, confusion_matrix, multilabel_confusion_matrix, classification_report, f1_score, precision_score, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import gc\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baddacbf-4517-46ad-83fd-90d4c1893f0e",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b2116f-b426-442e-872a-30021efc3b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1000 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7a65c9-cf89-4a9e-9c3e-c8b77bd7ff6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_CM(matrix):\n",
    "    \"\"\"\n",
    "    Visualize Correlation Matrix\n",
    "    \"\"\"\n",
    "    sns.heatmap(matrix,annot=True)\n",
    "\n",
    "def result_plot(_dict, name, folder, model_name):\n",
    "    \"\"\"\n",
    "    Plot results for multiclass classification\n",
    "    \"\"\"\n",
    "    with open('results_1000_mc.txt', 'a') as file:\n",
    "        file.write(f\"{name}: {_dict}\")\n",
    "    attacks = {}\n",
    "    higher = [\"F1\", \"Accuracy\", \"Precision\", \"Recall\", \"MCC\", \"precision\", \"recall\", \"f1-score\", \"support\", 'Benign', 'Bruteforce', 'DDoS', 'DoS', 'Mirai', 'Recon', 'Spoofing',\n",
    "       'Web']\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    if name in higher:\n",
    "        tmp = sorted(_dict.items(), key = lambda x:x[1])\n",
    "    else:\n",
    "        tmp = sorted(_dict.items(), key = lambda x:x[1], reverse=True)\n",
    "    for x in tmp:\n",
    "        attacks[x[0]] = x[1]\n",
    "    ax.bar(attacks.keys(), attacks.values())\n",
    "    rects = ax.patches\n",
    "    results = [i for i in attacks.values()]\n",
    "    labels = [f\"{results[i]:.6f}\" for i in range(len(rects))]\n",
    "    for rect, label in zip(rects, labels):\n",
    "        height = rect.get_height()\n",
    "        ax.text(\n",
    "            rect.get_x() + rect.get_width() / 2, height, label, ha=\"center\", va=\"bottom\"\n",
    "        )\n",
    "    if name in higher:\n",
    "        name = name.capitalize()\n",
    "        ax.set_title(f'{name} (higher is better)', fontsize=16, fontweight=\"bold\")\n",
    "    else:\n",
    "        ax.set_title(f'{name} (lower is better)', fontsize=16, fontweight=\"bold\")\n",
    "    ax.set_xlabel(f'{name}')\n",
    "    ax.set_ylabel('Score')\n",
    "    ax.grid(which='Major', axis='both')\n",
    "    ax.set_axisbelow(True)\n",
    "    if (model_name == \"\"):\n",
    "        plt.savefig(f\"images/results/{folder}/1000/{name}.png\")\n",
    "    else:\n",
    "        plt.savefig(f\"images/results/{folder}/1000/{name}_{model_name}.png\")\n",
    "\n",
    "def plot_mc(y_pred, y_test, model_name, mc_results = {}):\n",
    "    \"\"\"\n",
    "    Plots Precision, Recall and F1 scores for each class in multiclass classification\n",
    "    \"\"\"\n",
    "    cr = classification_report(y_pred, y_test, output_dict=True)\n",
    "    for key, name in cr.items():\n",
    "        if key not in ['accuracy', 'macro avg', 'weighted avg'] and int(key) in attack_dict:\n",
    "            mc_results[attack_dict[int(key)]] = cr[key]\n",
    "    mc_results = pd.DataFrame(mc_results).drop(['support'], axis = 0)\n",
    "    for key in mc_results.keys():\n",
    "        data_1000[key] = mc_results[key].to_dict()\n",
    "    x = pd.DataFrame(data_1000).transpose().to_dict()\n",
    "    with open('results_1000_precision.txt', 'a') as f:\n",
    "        f.write(f\"{model_name}: {x['precision']}\")\n",
    "    with open('results_1000_recall.txt', 'a') as f:\n",
    "        f.write(f\"{model_name}: {x['recall']}\")\n",
    "    with open('results_1000_f1.txt', 'a') as f:\n",
    "        f.write(f\"{model_name}: {x['f1-score']}\")\n",
    "    for key in mc_results.keys():\n",
    "        result_plot(mc_results[key], key, \"multiclass_by_class\", model_name)\n",
    "\n",
    "def measure_latency_cpu_usage(model, test_inputs):\n",
    "    process = psutil.Process()\n",
    "    cpu_start = process.cpu_percent()\n",
    "    start = time.time()\n",
    "    predictions = model.predict(test_inputs)\n",
    "    end = time.time()\n",
    "    cpu_end = process.cpu_percent()\n",
    "    latency = end - start\n",
    "    cpu_usage = cpu_end - cpu_start\n",
    "    return latency, cpu_usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb68e39a-2eb3-409f-95d7-20d002eeeedd",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07aa510b-c29b-4b76-b390-4ecd332ca92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/CIC_IoT2023/custom/multiclass_classification_data_1000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec8c75b-891a-4e95-a061-bac55478460b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['Unnamed: 0', 'label'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cad634-0ca7-4907-b8e9-c63900c9919d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ec8c27-d4e9-4c89-aab5-b78cf39e713f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6546f0ef-1c51-475c-9fa0-fceb2aa0f649",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['Attack Type'], axis = 1)\n",
    "y = data['Attack Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30cdc79-b862-4470-b6d0-be6824f13caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f327166-9006-4769-9a08-66b5ffa88a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987a4a9c-66ab-4f7b-ba98-e0d1ba4cc37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "data['Attack Number'] = le.fit_transform(y)\n",
    "y = data['Attack Number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f4df1a-8e3f-4bbe-a98a-08c5c4d35039",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97da960-1d16-4380-9c26-36b4ecf5f620",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_dict = {}\n",
    "encoded_values = data['Attack Number'].unique()\n",
    "for val in sorted(encoded_values):\n",
    "    attack_dict[val] = le.inverse_transform([val])[0]\n",
    "    print(f\"{val}: {le.inverse_transform([val])[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b20f7f-98a2-48be-9ded-806b15f37379",
   "metadata": {},
   "source": [
    "# Multiclass Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2557a7-fc75-46e7-bbd9-9c326d2dca5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8588246f-0b17-491e-a438-654bcaf92021",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1])\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1])\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9edada-eb38-4c94-9fb1-0bedc11c4f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique train values\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "for x, y in zip(unique, counts):\n",
    "    print(f\"{x}: {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0930b4ce-dd0c-444f-bfe9-edb054a48b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique train values\n",
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "for x, y in zip(unique, counts):\n",
    "    print(f\"{x}: {y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05aa6d6e-7921-424d-a886-a145ce015ee5",
   "metadata": {},
   "source": [
    "# K Nearest Neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c592cea2-b563-4037-ace0-c60007e4c994",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "knn_clf = KNeighborsClassifier(n_jobs=8)\n",
    "knn_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn_clf.predict(X_test)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "KNN_time = end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb27c030-7b36-42f2-81f4-50516991b0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_CM(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9091f4aa-919e-4553-a34b-5470e6f1673b",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "precision = precision_score(y_true=y_test, y_pred=y_pred, average=\"weighted\")\n",
    "f1 = f1_score(y_true=y_test, y_pred=y_pred, average=\"weighted\")\n",
    "recall = recall_score(y_true=y_test, y_pred=y_pred, average=\"weighted\")\n",
    "mcc = matthews_corrcoef(y_true=y_test,y_pred=y_pred)\n",
    "mae = mean_absolute_error(y_true=y_test,y_pred=y_pred)\n",
    "mse = mean_squared_error(y_true=y_test,y_pred=y_pred)\n",
    "rmse = root_mean_squared_error(y_true=y_test,y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30af44af-2513-463e-9d44-f83f8f39d485",
   "metadata": {},
   "outputs": [],
   "source": [
    "latency, cpu_usage = measure_latency_cpu_usage(knn_clf, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e8d193-e6fb-438e-9b26-6752513471b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [accuracy, precision, f1, recall, mcc, mae, mse, rmse, latency, KNN_time]\n",
    "results_dict[\"kNN\"] = results\n",
    "\n",
    "results_df = pd.DataFrame.from_dict(results_dict, orient=\"index\", columns=[\"Accuracy\", \"Precision\", \"F1\", \"Recall\", \"MCC\", \"MAE\", \"MSE\", \"RMSE\", \"Latency (ms)\", \"Time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbad820-3af0-4e8d-80b3-51b10c1adf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84603b22-1982-401a-ad52-92fdf5f67da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mc(y_pred, y_test, \"kNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5186cc8a-5962-4160-952e-f6a5e54f48a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"kNN_1000.sav\"\n",
    "pickle.dump(knn_clf, open(model_name, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28da2705-012f-4048-840f-0c894a3da693",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c71021-619e-404e-92ca-050339b053b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "lr_clf = LogisticRegression(max_iter = 10000, C = 0.1, random_state = 0, solver = 'saga', n_jobs=8)\n",
    "lr_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr_clf.predict(X_test)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "LR_time = end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f477a3-0862-4fb9-92ea-159f720bb633",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_CM(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98378824-c895-4165-9a16-ddf7b865a7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "precision = precision_score(y_true=y_test, y_pred=y_pred, average=\"weighted\")\n",
    "f1 = f1_score(y_true=y_test, y_pred=y_pred, average=\"weighted\")\n",
    "recall = recall_score(y_true=y_test, y_pred=y_pred, average=\"weighted\")\n",
    "mcc = matthews_corrcoef(y_true=y_test,y_pred=y_pred)\n",
    "mae = mean_absolute_error(y_true=y_test,y_pred=y_pred)\n",
    "mse = mean_squared_error(y_true=y_test,y_pred=y_pred)\n",
    "rmse = root_mean_squared_error(y_true=y_test,y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a48865-aaf9-449d-a51f-49bd5131c7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "latency, cpu_usage = measure_latency_cpu_usage(lr_clf, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a129c514-d4fe-4f5e-b01b-9245604b50c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [accuracy, precision, f1, recall, mcc, mae, mse, rmse, latency, LR_time]\n",
    "results_dict[\"LR\"] = results\n",
    "\n",
    "results_df = pd.DataFrame.from_dict(results_dict, orient=\"index\", columns=[\"Accuracy\", \"Precision\", \"F1\", \"Recall\", \"MCC\", \"MAE\", \"MSE\", \"RMSE\", \"Latency (ms)\", \"Time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941f9f7b-01b0-487c-9978-f6c08a7fb7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ba0f8b-fca9-4a94-97ff-33710bb696d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mc(y_pred, y_test, \"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9f0338-3fc1-424a-9ae8-e401298a73a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"LR_1000.sav\"\n",
    "pickle.dump(lr_clf, open(model_name, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755d36cd-eaed-4dc4-b2a0-ee0ca17856ea",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564de985-fe44-43d4-89b2-be5267bd4142",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_jobs=8)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "RF_time = end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4259d9f5-8138-41ee-a191-b5348b57995d",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_CM(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1eeec6a-1b48-4eab-85cd-cd26f3b1e592",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "precision = precision_score(y_true=y_test, y_pred=y_pred, average=\"weighted\")\n",
    "f1 = f1_score(y_true=y_test, y_pred=y_pred, average=\"weighted\")\n",
    "recall = recall_score(y_true=y_test, y_pred=y_pred, average=\"weighted\")\n",
    "mcc = matthews_corrcoef(y_true=y_test,y_pred=y_pred)\n",
    "mae = mean_absolute_error(y_true=y_test,y_pred=y_pred)\n",
    "mse = mean_squared_error(y_true=y_test,y_pred=y_pred)\n",
    "rmse = root_mean_squared_error(y_true=y_test,y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bed66c-2e90-40ae-8b0f-afde6512b6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "latency, cpu_usage = measure_latency_cpu_usage(rf_clf, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da8dee3-7f70-460c-b745-a907a0526e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [accuracy, precision, f1, recall, mcc, mae, mse, rmse, latency, RF_time]\n",
    "results_dict[\"RF\"] = results\n",
    "\n",
    "results_df = pd.DataFrame.from_dict(results_dict, orient=\"index\", columns=[\"Accuracy\", \"Precision\", \"F1\", \"Recall\", \"MCC\", \"MAE\", \"MSE\", \"RMSE\", \"Latency (ms)\", \"Time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b74ceb-e3f7-4168-8472-e52f497871f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c3b5d3-d943-4f27-8c2d-e419f5dba28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mc(y_pred, y_test, \"RF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4dc36b-b5d7-403c-94f8-f110b504f179",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"RF_1000.sav\"\n",
    "pickle.dump(rf_clf, open(model_name, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913ea60d-8dba-4b9d-ac1c-30ce21d6982f",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd29c598-45be-4466-b7ce-d108f4c38ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier()\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgb_clf.predict(X_test)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "XGB_time = end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a11fdc-62ce-4b4d-95d6-7ece0fb3ed8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_CM(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ade5b83-35a0-442f-b8db-7a70d82a10b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "precision = precision_score(y_true=y_test, y_pred=y_pred, average=\"weighted\")\n",
    "f1 = f1_score(y_true=y_test, y_pred=y_pred, average=\"weighted\")\n",
    "recall = recall_score(y_true=y_test, y_pred=y_pred, average=\"weighted\")\n",
    "mcc = matthews_corrcoef(y_true=y_test,y_pred=y_pred)\n",
    "mae = mean_absolute_error(y_true=y_test,y_pred=y_pred)\n",
    "mse = mean_squared_error(y_true=y_test,y_pred=y_pred) \n",
    "rmse = root_mean_squared_error(y_true=y_test,y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff87e728-3135-4299-9cae-77669845c0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "latency, cpu_usage = measure_latency_cpu_usage(xgb_clf, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8369d53e-8949-4006-bf41-b4b15576c639",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [accuracy, precision, f1, recall, mcc, mae, mse, rmse, latency, XGB_time]\n",
    "results_dict[\"XGBoost\"] = results\n",
    "\n",
    "results_df = pd.DataFrame.from_dict(results_dict, orient=\"index\", columns=[\"Accuracy\", \"Precision\", \"F1\", \"Recall\", \"MCC\", \"MAE\", \"MSE\", \"RMSE\", \"Latency (ms)\", \"Time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cbb192-98a5-4411-9f0a-838e700f6f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9021356-51e9-4912-8626-edcea166bf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mc(y_pred, y_test, \"XGBoost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34973d75-fc20-4bf2-bbb0-3438e8855aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"XGB_1000.sav\"\n",
    "pickle.dump(xgb_clf, open(model_name, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097b3a44-8130-4e33-a521-f26a1a56a326",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d48a7b0-602d-448d-9eed-37a015f8e7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "lgbm_clf = lightgbm.LGBMClassifier()\n",
    "lgbm_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lgbm_clf.predict(X_test)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "LightGBM_Time = end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce3d51e-488c-4f12-beea-9b75318e042d",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_CM(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5a2793-9ddc-4e30-98f7-9dac5196ed0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "precision = precision_score(y_true=y_test, y_pred=y_pred, average=\"weighted\")\n",
    "f1 = f1_score(y_true=y_test, y_pred=y_pred, average=\"weighted\")\n",
    "recall = recall_score(y_true=y_test, y_pred=y_pred, average=\"weighted\")\n",
    "mcc = matthews_corrcoef(y_true=y_test,y_pred=y_pred)\n",
    "mae = mean_absolute_error(y_true=y_test,y_pred=y_pred)\n",
    "mse = mean_squared_error(y_true=y_test,y_pred=y_pred) \n",
    "rmse = root_mean_squared_error(y_true=y_test,y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701c9986-7561-4a86-9040-2d1c4019f8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "latency, cpu_usage = measure_latency_cpu_usage(lgbm_clf, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb635bb6-88b8-4030-baca-bedc50c564eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [accuracy, precision, f1, recall, mcc, mae, mse, rmse, latency, LightGBM_Time]\n",
    "results_dict[\"LightGBM\"] = results\n",
    "\n",
    "results_df = pd.DataFrame.from_dict(results_dict, orient=\"index\", columns=[\"Accuracy\", \"Precision\", \"F1\", \"Recall\", \"MCC\", \"MAE\", \"MSE\", \"RMSE\", \"Latency (ms)\", \"Time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874d1958-8226-4e76-a35d-0c8d3cb0dc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b4a5dc-67ca-4b6b-ac09-276587db7f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mc(y_pred, y_test, \"LightGBM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9809e033-ea0f-4b58-9a5b-d52e77d9075d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"LightGBM_1000.sav\"\n",
    "pickle.dump(lgbm_clf, open(model_name, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a848b826-c38b-4bc9-a974-5d4d75e561ce",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e139e3-7b52-40c9-a5fc-c791c8775059",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "svm_clf = SVC(kernel = 'poly', C = 1, random_state = 0, probability = True)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svm_clf.predict(X_test)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "SVM_Time = end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15f0d11-9c9d-431f-86ab-b5190eeba516",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_CM(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5246dd4-ca06-4615-be37-19c67a11308f",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "precision = precision_score(y_true=y_test, y_pred=y_pred, average=\"weighted\")\n",
    "f1 = f1_score(y_true=y_test, y_pred=y_pred, average=\"weighted\")\n",
    "recall = recall_score(y_true=y_test, y_pred=y_pred, average=\"weighted\")\n",
    "mcc = matthews_corrcoef(y_true=y_test,y_pred=y_pred)\n",
    "mae = mean_absolute_error(y_true=y_test,y_pred=y_pred)\n",
    "mse = mean_squared_error(y_true=y_test,y_pred=y_pred) \n",
    "rmse = root_mean_squared_error(y_true=y_test,y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3bbfb6-eebe-4c75-b30b-e574be43f2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "latency, cpu_usage = measure_latency_cpu_usage(svm_clf, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d95cde-13d2-4ffc-a322-f50d742afa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [accuracy, precision, f1, recall, mcc, mae, mse, rmse, latency, SVM_Time]\n",
    "results_dict[\"SVM\"] = results\n",
    "\n",
    "results_df = pd.DataFrame.from_dict(results_dict, orient=\"index\", columns=[\"Accuracy\", \"Precision\", \"F1\", \"Recall\", \"MCC\", \"MAE\", \"MSE\", \"RMSE\", \"Latency (ms)\", \"Time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25275e78-6ae5-4fca-9c74-d6676e97d373",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c3fe30-5e40-44f0-ae29-5e97dbb98105",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mc(y_pred, y_test, \"SVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb4e5f2-2337-4867-846b-5d1cf708650a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"SVM_1000.sav\"\n",
    "pickle.dump(svm_clf, open(model_name, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2340ec3a-6c96-4650-81d4-c4019883fe3d",
   "metadata": {},
   "source": [
    "# Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5213512-1c62-4ce1-8be8-c62e30ca2aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['Attack Type'], axis = 1)\n",
    "y = data['Attack Type']\n",
    "\n",
    "data['Attack Number'] = le.fit_transform(y)\n",
    "y = data['Attack Number']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fc6887-217d-4081-ae08-e3c1c72534e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.18)\n",
    "X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ce321d-a2a2-4a3f-bca9-4afd5590b6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(X_train, y_train):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(X_train.shape[1], activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    model.add(keras.layers.Dense(1024, activation='relu'))\n",
    "    model.add(keras.layers.Dense(512, activation='relu'))\n",
    "    model.add(keras.layers.Dense(len(np.unique(y_train)), activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "model = create_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d0a685-755c-448c-a9f2-11d05d107e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048819c7-3fee-483b-822c-e49b64600293",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=16,\n",
    "          epochs=20,\n",
    "          validation_data=(X_val, y_val))\n",
    "gc.collect();\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "FFNN_Time = end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cb7ebe-b2cb-43d0-a541-fad372c5cc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593eb9fd-c4c1-44a2-965a-10e7a1ba2750",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, accuracy = model.evaluate(X_test, y_test)\n",
    "precision = precision_score(y_true=y_test, y_pred=y_pred, average=\"weighted\")\n",
    "f1 = f1_score(y_true=y_test, y_pred=y_pred, average=\"weighted\")\n",
    "recall = recall_score(y_true=y_test, y_pred=y_pred, average=\"weighted\")\n",
    "mcc = matthews_corrcoef(y_true=y_test,y_pred=y_pred)\n",
    "mae = mean_absolute_error(y_true=y_test,y_pred=y_pred)\n",
    "mse = mean_squared_error(y_true=y_test,y_pred=y_pred) \n",
    "rmse = root_mean_squared_error(y_true=y_test,y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5896735-39e3-4ee6-baf7-a42cc8d615bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "latency, cpu_usage = measure_latency_cpu_usage(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a011fde5-0280-4b83-9ca5-9da7a86519dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [accuracy, precision, f1, recall, mcc, mae, mse, rmse, latency, FFNN_Time]\n",
    "results_dict[\"FF-NN\"] = results\n",
    "\n",
    "results_df = pd.DataFrame.from_dict(results_dict, orient=\"index\", columns=[\"Accuracy\", \"Precision\", \"F1\", \"Recall\", \"MCC\", \"MAE\", \"MSE\", \"RMSE\", \"Latency (ms)\", \"Time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d048e978-204d-43e0-b6e5-aae74bd52f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10622d2f-faf5-4065-b641-610a62ae2bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mc(y_pred, y_test, \"FF-NN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac73b4d7-c5b7-4670-8f3a-f426f86a40dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"FFNN_1000.sav\"\n",
    "pickle.dump(model, open(model_name, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9faf3e-6103-48d9-8f36-a6abe0a5f875",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8c0d22-12bc-4a57-a4c7-eab96190a1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare sequential data\n",
    "def create_sequences(features, labels, seq_length):\n",
    "    sequences, seq_labels = [], []\n",
    "    for i in range(len(features) - seq_length):\n",
    "        sequences.append(features[i:i + seq_length])\n",
    "        seq_labels.append(labels[i + seq_length - 1])  # Use the last label in the sequence\n",
    "    return np.array(sequences), np.array(seq_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82724043-9ec5-46e6-8346-d23bd5f8990a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_components = len(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dada09fb-c7ba-47b1-8d3b-234147a2dbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequences\n",
    "seq_length = 20\n",
    "X1, y1 = create_sequences(X, y, seq_length)\n",
    "y1 = to_categorical(y1, num_classes=num_components)  # Convert labels to one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2527dc-2536-485a-9eed-79cf58e78854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X1, y1, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77da2542-0a2b-4e83-8ec3-143bbd1efb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_LSTM(input_shape, num_classes):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.LSTM(64, input_shape=input_shape, return_sequences=True),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.LSTM(32),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(64, activation='relu'),\n",
    "        keras.layers.Dense(num_classes, activation='softmax')  # Use softmax for multi-class classification\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da786b90-2a38-42ff-883c-6c3a9e5f558c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "model = create_model_LSTM(input_shape=(seq_length, X1.shape[2]), num_classes=num_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a372786-4b22-4f6f-a7a5-41e500c8db09",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37ff570-df00-4056-a259-8127b08cb803",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, y_val)\n",
    ")\n",
    "\n",
    "# Evaluate model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "LSTM_Time = end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ba72f2-c86a-4f2d-b420-5be108aa7e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, accuracy = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5656cb4-cbd1-4eb1-916b-023e5c209ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "latency, cpu_usage = measure_latency_cpu_usage(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d025a10e-7a48-4916-ab43-9c583da04468",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.argmax(y_test, axis=1)\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136c5361-7749-4a5e-869e-81a88683e445",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = precision_score(y_true=y_test, y_pred=y_pred, average=\"weighted\")\n",
    "f1 = f1_score(y_true=y_test, y_pred=y_pred, average=\"weighted\")\n",
    "recall = recall_score(y_true=y_test, y_pred=y_pred, average=\"weighted\")\n",
    "mcc = matthews_corrcoef(y_true=y_test,y_pred=y_pred)\n",
    "mae = mean_absolute_error(y_true=y_test,y_pred=y_pred)\n",
    "mse = mean_squared_error(y_true=y_test,y_pred=y_pred) \n",
    "rmse = root_mean_squared_error(y_true=y_test,y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943e07af-c7ce-4961-b8d0-90ce88b2a14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [accuracy, precision, f1, recall, mcc, mae, mse, rmse, latency, LSTM_Time]\n",
    "results_dict[\"LSTM\"] = results\n",
    "\n",
    "results_df = pd.DataFrame.from_dict(results_dict, orient=\"index\", columns=[\"Accuracy\", \"Precision\", \"F1\", \"Recall\", \"MCC\", \"MAE\", \"MSE\", \"RMSE\", \"Latency (ms)\", \"Time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f74780c-52d9-4226-9b50-2fe066985b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693b7312-2f0a-4c04-ba29-1d55bd6d21a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mc(y_pred, y_test, \"LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ac74c4-8811-4b89-8843-876e06a49bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"LSTM_1000.sav\"\n",
    "pickle.dump(model, open(model_name, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488d9c7b-992f-4b9a-8cb2-1c61bd1cca71",
   "metadata": {},
   "source": [
    "# Plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c96855e-a6ca-48ff-b6ba-0e668eb44455",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame.from_dict(results_dict, orient=\"index\", columns=[\"Accuracy\", \"Precision\", \"F1\", \"Recall\", \"MCC\", \"MAE\", \"MSE\", \"RMSE\", \"Latency (ms)\", \"Time\"])\n",
    "for x in results_df:\n",
    "    _dict = {}\n",
    "    name = results_df[x].name\n",
    "    for keys, values in zip(range(len(results_df[x].keys())), results_df[x]):\n",
    "        _dict[results_df[x].keys()[keys]] = values\n",
    "    result_plot(_dict, name, \"multiclass\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846621d5-6807-4841-ba6a-bcccc71a99e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
